{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4637521,"sourceType":"datasetVersion","datasetId":2697382},{"sourceId":4785628,"sourceType":"datasetVersion","datasetId":2770243}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install twarc\n!pip install transformers==3","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:41:46.122926Z","iopub.execute_input":"2022-12-31T18:41:46.123294Z","iopub.status.idle":"2022-12-31T18:42:05.029734Z","shell.execute_reply.started":"2022-12-31T18:41:46.123262Z","shell.execute_reply":"2022-12-31T18:42:05.028454Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting transformers==3\n  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.6/754.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers==3) (0.1.97)\nCollecting tokenizers==0.8.0-rc4\n  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3) (4.64.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3) (2021.11.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3) (21.3)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3) (0.0.53)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3) (2.28.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3) (1.21.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3) (2.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3) (1.0.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==3) (4.13.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3) (3.8.0)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.12.1\n    Uninstalling tokenizers-0.12.1:\n      Successfully uninstalled tokenizers-0.12.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.8.0rc4 transformers-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom transformers import BertTokenizer, BertModel\nimport re\nfrom nltk.corpus import stopwords\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom torch import cuda\n\ndevice = 'cuda' if cuda.is_available() else 'cpu'\n#from twarc import Twarc\n'''data = pd.read_csv('/kaggle/input/the-climate-change-twitter-dataset/The Climate Change Twitter Dataset.csv')\ndata = data.dropna()\ndata = data.sample(frac=1)\ndata = data.iloc[:5000]'''","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:05.033207Z","iopub.execute_input":"2022-12-31T18:42:05.033959Z","iopub.status.idle":"2022-12-31T18:42:18.724599Z","shell.execute_reply.started":"2022-12-31T18:42:05.033918Z","shell.execute_reply":"2022-12-31T18:42:18.723519Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\nThe current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","output_type":"stream"},{"name":"stdout","text":"The current process just got forked. Disabling parallelism to avoid deadlocks...\nTo disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\"data = pd.read_csv('/kaggle/input/the-climate-change-twitter-dataset/The Climate Change Twitter Dataset.csv')\\ndata = data.dropna()\\ndata = data.sample(frac=1)\\ndata = data.iloc[:5000]\""},"metadata":{}}]},{"cell_type":"code","source":"'''consumer_key=\"mgUcSHDYZ228CbYKyUm9X1Cia\"\nconsumer_secret=\"WKPkWZSBmb2cwrGYiZZU3dYlXEq93n0hlTyQm8u90HwtRtUZcy\"\naccess_token=\"1596162900837761025-ibC5Jebjm8bf9hk2W0VeSXpxH6DJu0\"\naccess_token_secret=\"a0KZOaIcLWDspbOcd167jsxKiTh7E6c7cnbBLW57EPtBc\"\ncontent = list()\nids = list()\nt = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n\nfor tweet in t.hydrate(data.id) :\n    content.append(tweet['full_text'])\n    ids.append(tweet['id'])'''","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:18.726474Z","iopub.execute_input":"2022-12-31T18:42:18.727337Z","iopub.status.idle":"2022-12-31T18:42:18.741477Z","shell.execute_reply.started":"2022-12-31T18:42:18.727306Z","shell.execute_reply":"2022-12-31T18:42:18.735460Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'consumer_key=\"mgUcSHDYZ228CbYKyUm9X1Cia\"\\nconsumer_secret=\"WKPkWZSBmb2cwrGYiZZU3dYlXEq93n0hlTyQm8u90HwtRtUZcy\"\\naccess_token=\"1596162900837761025-ibC5Jebjm8bf9hk2W0VeSXpxH6DJu0\"\\naccess_token_secret=\"a0KZOaIcLWDspbOcd167jsxKiTh7E6c7cnbBLW57EPtBc\"\\ncontent = list()\\nids = list()\\nt = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\\n\\nfor tweet in t.hydrate(data.id) :\\n    content.append(tweet[\\'full_text\\'])\\n    ids.append(tweet[\\'id\\'])'"},"metadata":{}}]},{"cell_type":"code","source":"'''print(len(content))\ndrop_ids = set(data.id).difference(set(ids))\nfor i in drop_ids :\n    data = data.loc[data['id'] != i]\nprint(len(data))\n\ndata['Content'] = content\ndata.to_csv('/kaggle/working/tweet-data.csv',index=False)'''","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:18.745714Z","iopub.execute_input":"2022-12-31T18:42:18.746009Z","iopub.status.idle":"2022-12-31T18:42:18.788804Z","shell.execute_reply.started":"2022-12-31T18:42:18.745983Z","shell.execute_reply":"2022-12-31T18:42:18.787369Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"print(len(content))\\ndrop_ids = set(data.id).difference(set(ids))\\nfor i in drop_ids :\\n    data = data.loc[data['id'] != i]\\nprint(len(data))\\n\\ndata['Content'] = content\\ndata.to_csv('/kaggle/working/tweet-data.csv',index=False)\""},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n#tweets = pd.read_csv('/kaggle/input/climate-tweets/climate_tweets.csv')\n#tweets = tweets.drop(['URL','Likes','Retweets'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:18.789954Z","iopub.execute_input":"2022-12-31T18:42:18.791459Z","iopub.status.idle":"2022-12-31T18:42:37.988684Z","shell.execute_reply.started":"2022-12-31T18:42:18.791430Z","shell.execute_reply":"2022-12-31T18:42:37.987451Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa258e5e5ead42c0a31f21465109df94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a188951614dd4f6db51a2ebc44af2770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e058fc9d90a64e03acb7a7b3be32b2ed"}},"metadata":{}}]},{"cell_type":"code","source":"import inspect\nprint(inspect.getargspec(model))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:37.990351Z","iopub.execute_input":"2022-12-31T18:42:37.991105Z","iopub.status.idle":"2022-12-31T18:42:37.999419Z","shell.execute_reply.started":"2022-12-31T18:42:37.991060Z","shell.execute_reply":"2022-12-31T18:42:37.998212Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"ArgSpec(args=['self'], varargs='input', keywords='kwargs', defaults=None)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"tweets = pd.read_csv('/kaggle/input/tweetdata/tweet-data.csv')\ntweets = tweets.drop(['topic','gender','temperature_avg','aggressiveness'],axis=1)\nmentions = \"^(RT|rt)( @\\w*)?[: ]\"\nhashtags = \"#([a-zA-Z0-9_]{1,50})\"\npunctuations = string.punctuation\nstop_words = set(stopwords.words('english'))\n\n# remove @ and # texts\ntweets['Content'] = tweets['Content'].apply(lambda x : re.sub(mentions,'',x))\ntweets['Content'] = tweets['Content'].apply(lambda x : re.sub(hashtags,'',x))\ntweets['Content'] = tweets['Content'].apply(lambda x : x.lower())\n\n#removing digits and punctuations\n#tweets['Content'] = tweets['Content'].apply(lambda x : re.sub('[0-9]','',x))        \n#tweets['Content'] = tweets['Content'].apply(lambda x : re.sub('[^\\w\\s]','',x))\n\n#remove stop words\ndef remove_stopwords(text) :\n    cleaned = []\n    for word in word_tokenize(text) :\n        if word not in stop_words :\n            cleaned.append(word)\n            \n    return ' '.join(cleaned)\n\n#tweets['Content'] = tweets['Content'].apply(remove_stopwords)\nprint(tweets)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:38.001294Z","iopub.execute_input":"2022-12-31T18:42:38.002616Z","iopub.status.idle":"2022-12-31T18:42:38.195388Z","shell.execute_reply.started":"2022-12-31T18:42:38.002571Z","shell.execute_reply":"2022-12-31T18:42:38.194083Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"                     created_at                   id         lng        lat  \\\n0     2017-12-09 18:42:56+00:00   939566047677394944 -123.186770  44.851230   \n1     2019-05-18 12:05:32+00:00  1129719667281547265  -71.214540  46.812280   \n2     2018-10-08 23:20:52+00:00  1049439513339092992  151.207320 -33.867850   \n3     2016-11-01 15:16:57+00:00   793471897639923712 -122.419906  37.779026   \n4     2010-10-01 09:59:49+00:00          26065785509    8.801290  48.823980   \n...                         ...                  ...         ...        ...   \n4361  2019-05-11 03:33:09+00:00  1127054005115342848  -74.006015  40.712728   \n4362  2019-05-09 03:56:26+00:00  1126335089338671104  -95.992770  36.153980   \n4363  2019-05-14 06:24:02+00:00  1128184174441930752  153.028090 -27.467940   \n4364  2016-06-25 07:26:30+00:00   746605472510255104  -85.759410  38.254240   \n4365  2018-01-03 15:55:21+00:00   948583570569707521   72.504510  23.014800   \n\n      sentiment    stance                                            Content  \n0      0.484304  believer  @hanamichels like climate change, there’s beli...  \n1      0.759282  believer   heatwave seems to make manmade climate change...  \n2     -0.579046  believer  don't blame wildfires on climate change – it's...  \n3     -0.413409   neutral   ojo! in 1912 scientists warned of us coal and...  \n4     -0.066502  believer   influencers! have you registered for @climate...  \n...         ...       ...                                                ...  \n4361   0.428099  believer   does anyone think global warming is a good th...  \n4362  -0.467969   neutral   yea your nudes fire but what are u doing to s...  \n4363  -0.646242  believer  impakterdotcom \"rt sierraclub: \"pre-disaster m...  \n4364   0.048020  believer  “the important question for australia, then, i...  \n4365   0.550023  believer  my dearest martha: the office is stifling. the...  \n\n[4366 rows x 7 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"#tweets['Content'] = tweets['Content'].apply(lambda x : sent_tokenize(x))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:38.196839Z","iopub.execute_input":"2022-12-31T18:42:38.197527Z","iopub.status.idle":"2022-12-31T18:42:38.202997Z","shell.execute_reply.started":"2022-12-31T18:42:38.197486Z","shell.execute_reply":"2022-12-31T18:42:38.201671Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n# Create tokenized column\ntweets['len'] = tweets['Content'].apply(lambda x : len(x))\ntweets = tweets.drop(tweets.index[(tweets['len'] == 0)],axis=0)\ntweets['tokenize_ID'] = tweets['Content'].apply(lambda x : tokenizer(x ,padding=\"max_length\", truncation=True))\n#tweets['tokens'] = tweets['Content'].apply(lambda x : tokenizer.convert_ids_to_tokens(tokenizer.encode(x)))\ntweets","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:42:38.204380Z","iopub.execute_input":"2022-12-31T18:42:38.205323Z","iopub.status.idle":"2022-12-31T18:42:41.359638Z","shell.execute_reply.started":"2022-12-31T18:42:38.205284Z","shell.execute_reply":"2022-12-31T18:42:41.358955Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                     created_at                   id         lng        lat  \\\n0     2017-12-09 18:42:56+00:00   939566047677394944 -123.186770  44.851230   \n1     2019-05-18 12:05:32+00:00  1129719667281547265  -71.214540  46.812280   \n2     2018-10-08 23:20:52+00:00  1049439513339092992  151.207320 -33.867850   \n3     2016-11-01 15:16:57+00:00   793471897639923712 -122.419906  37.779026   \n4     2010-10-01 09:59:49+00:00          26065785509    8.801290  48.823980   \n...                         ...                  ...         ...        ...   \n4361  2019-05-11 03:33:09+00:00  1127054005115342848  -74.006015  40.712728   \n4362  2019-05-09 03:56:26+00:00  1126335089338671104  -95.992770  36.153980   \n4363  2019-05-14 06:24:02+00:00  1128184174441930752  153.028090 -27.467940   \n4364  2016-06-25 07:26:30+00:00   746605472510255104  -85.759410  38.254240   \n4365  2018-01-03 15:55:21+00:00   948583570569707521   72.504510  23.014800   \n\n      sentiment    stance                                            Content  \\\n0      0.484304  believer  @hanamichels like climate change, there’s beli...   \n1      0.759282  believer   heatwave seems to make manmade climate change...   \n2     -0.579046  believer  don't blame wildfires on climate change – it's...   \n3     -0.413409   neutral   ojo! in 1912 scientists warned of us coal and...   \n4     -0.066502  believer   influencers! have you registered for @climate...   \n...         ...       ...                                                ...   \n4361   0.428099  believer   does anyone think global warming is a good th...   \n4362  -0.467969   neutral   yea your nudes fire but what are u doing to s...   \n4363  -0.646242  believer  impakterdotcom \"rt sierraclub: \"pre-disaster m...   \n4364   0.048020  believer  “the important question for australia, then, i...   \n4365   0.550023  believer  my dearest martha: the office is stifling. the...   \n\n      len                                  tokenize_ID  \n0      79  [input_ids, token_type_ids, attention_mask]  \n1      89  [input_ids, token_type_ids, attention_mask]  \n2     107  [input_ids, token_type_ids, attention_mask]  \n3     114  [input_ids, token_type_ids, attention_mask]  \n4     203  [input_ids, token_type_ids, attention_mask]  \n...   ...                                          ...  \n4361  112  [input_ids, token_type_ids, attention_mask]  \n4362   76  [input_ids, token_type_ids, attention_mask]  \n4363  182  [input_ids, token_type_ids, attention_mask]  \n4364  301  [input_ids, token_type_ids, attention_mask]  \n4365  195  [input_ids, token_type_ids, attention_mask]  \n\n[4365 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lng</th>\n      <th>lat</th>\n      <th>sentiment</th>\n      <th>stance</th>\n      <th>Content</th>\n      <th>len</th>\n      <th>tokenize_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-12-09 18:42:56+00:00</td>\n      <td>939566047677394944</td>\n      <td>-123.186770</td>\n      <td>44.851230</td>\n      <td>0.484304</td>\n      <td>believer</td>\n      <td>@hanamichels like climate change, there’s beli...</td>\n      <td>79</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-05-18 12:05:32+00:00</td>\n      <td>1129719667281547265</td>\n      <td>-71.214540</td>\n      <td>46.812280</td>\n      <td>0.759282</td>\n      <td>believer</td>\n      <td>heatwave seems to make manmade climate change...</td>\n      <td>89</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-10-08 23:20:52+00:00</td>\n      <td>1049439513339092992</td>\n      <td>151.207320</td>\n      <td>-33.867850</td>\n      <td>-0.579046</td>\n      <td>believer</td>\n      <td>don't blame wildfires on climate change – it's...</td>\n      <td>107</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-11-01 15:16:57+00:00</td>\n      <td>793471897639923712</td>\n      <td>-122.419906</td>\n      <td>37.779026</td>\n      <td>-0.413409</td>\n      <td>neutral</td>\n      <td>ojo! in 1912 scientists warned of us coal and...</td>\n      <td>114</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-10-01 09:59:49+00:00</td>\n      <td>26065785509</td>\n      <td>8.801290</td>\n      <td>48.823980</td>\n      <td>-0.066502</td>\n      <td>believer</td>\n      <td>influencers! have you registered for @climate...</td>\n      <td>203</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4361</th>\n      <td>2019-05-11 03:33:09+00:00</td>\n      <td>1127054005115342848</td>\n      <td>-74.006015</td>\n      <td>40.712728</td>\n      <td>0.428099</td>\n      <td>believer</td>\n      <td>does anyone think global warming is a good th...</td>\n      <td>112</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>4362</th>\n      <td>2019-05-09 03:56:26+00:00</td>\n      <td>1126335089338671104</td>\n      <td>-95.992770</td>\n      <td>36.153980</td>\n      <td>-0.467969</td>\n      <td>neutral</td>\n      <td>yea your nudes fire but what are u doing to s...</td>\n      <td>76</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>4363</th>\n      <td>2019-05-14 06:24:02+00:00</td>\n      <td>1128184174441930752</td>\n      <td>153.028090</td>\n      <td>-27.467940</td>\n      <td>-0.646242</td>\n      <td>believer</td>\n      <td>impakterdotcom \"rt sierraclub: \"pre-disaster m...</td>\n      <td>182</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>4364</th>\n      <td>2016-06-25 07:26:30+00:00</td>\n      <td>746605472510255104</td>\n      <td>-85.759410</td>\n      <td>38.254240</td>\n      <td>0.048020</td>\n      <td>believer</td>\n      <td>“the important question for australia, then, i...</td>\n      <td>301</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n    <tr>\n      <th>4365</th>\n      <td>2018-01-03 15:55:21+00:00</td>\n      <td>948583570569707521</td>\n      <td>72.504510</td>\n      <td>23.014800</td>\n      <td>0.550023</td>\n      <td>believer</td>\n      <td>my dearest martha: the office is stifling. the...</td>\n      <td>195</td>\n      <td>[input_ids, token_type_ids, attention_mask]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4365 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i,stance in enumerate(tweets.stance) :\n    if stance == 'neutral':\n        tweets['stance'].iloc[i] = [0,1,0]\n    elif stance == 'believer' :\n        tweets['stance'].iloc[i] = [0,0,1]\n    elif stance == 'denier' :\n        tweets['stance'].iloc[i] = [1,0,0]\n\ntrain, test, evaluate = np.split(tweets.sample(frac=1), [3999,4182])\nclass BertDataset(Dataset) :\n    def __init__(self,data) :\n        self.data = data\n        self.tokenized = self.data.tokenize_ID\n        self.label = self.data.stance\n    \n    def __len__(self) :\n        return len(self.tokenized)\n    \n    def __getitem__(self,idx) :\n        if torch.is_tensor(idx) :\n            idx = idx.to_list()\n            \n        item = self.tokenized.iloc[idx]\n        label = self.label.iloc[idx]\n        sample = {\n                  \"input_ids\" : torch.tensor(item['input_ids'],dtype=torch.long),\n                  \"token_type_ids\" : torch.tensor(item['token_type_ids'],dtype=torch.long),\n                  \"attention_mask\" : torch.tensor(item['attention_mask'],dtype=torch.long),\n                  \"label\" : torch.tensor(label,dtype=torch.long)\n                }\n\n        return sample\n\ntraining_data = BertDataset(train)\ntesting_data = BertDataset(test)\n\ntrain_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\ntest_dataloader = DataLoader(testing_data, batch_size=4, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:46:04.970338Z","iopub.execute_input":"2022-12-31T18:46:04.971091Z","iopub.status.idle":"2022-12-31T18:46:05.072645Z","shell.execute_reply.started":"2022-12-31T18:46:04.971053Z","shell.execute_reply":"2022-12-31T18:46:05.071240Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n    \nclass BERT(torch.nn.Module):\n    def __init__(self,model):\n        super(BERT, self).__init__()\n        self.l1 = model\n        self.l2 = torch.nn.Dropout(0.3)\n        self.l3 = torch.nn.Linear(768, 3)\n    \n    def forward(self, ids, mask):\n        _, output_1= self.l1(input_ids=ids, attention_mask=mask)\n        output_1 = torch.tensor(output_1)\n        output_2 = self.l2(output_1)\n        output = self.l3(output_2)\n        return output\n    \n\nmodel = BERT(model=model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:37:50.971426Z","iopub.execute_input":"2022-12-31T16:37:50.971798Z","iopub.status.idle":"2022-12-31T16:37:59.097106Z","shell.execute_reply.started":"2022-12-31T16:37:50.971759Z","shell.execute_reply":"2022-12-31T16:37:59.096032Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"BERT(\n  (l1): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (l2): Dropout(p=0.3, inplace=False)\n  (l3): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.CrossEntropyLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-5)\n\ndef train(epoch):\n    model.train()\n    for _,data in enumerate(train_dataloader, 0):\n        ids = data['input_ids'].to(device, dtype = torch.long)\n        mask = data['attention_mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['label'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        if _%5000==0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2022-12-31T17:02:40.653400Z","iopub.execute_input":"2022-12-31T17:02:40.653791Z","iopub.status.idle":"2022-12-31T17:02:40.664893Z","shell.execute_reply.started":"2022-12-31T17:02:40.653757Z","shell.execute_reply":"2022-12-31T17:02:40.663868Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for epoch in range(4):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T17:02:45.231687Z","iopub.execute_input":"2022-12-31T17:02:45.232069Z","iopub.status.idle":"2022-12-31T17:11:46.556745Z","shell.execute_reply.started":"2022-12-31T17:02:45.232036Z","shell.execute_reply":"2022-12-31T17:11:46.555764Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  del sys.path[0]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Loss:  0.21144327521324158\nEpoch: 1, Loss:  1.4781180620193481\nEpoch: 2, Loss:  0.6440751552581787\nEpoch: 3, Loss:  0.6523970365524292\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\ndef validation(epoch):\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(test_dataloader, 0):\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['label'].to(device, dtype = torch.float)\n            outputs = model(ids, mask)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:41:15.035408Z","iopub.execute_input":"2022-12-31T18:41:15.036047Z","iopub.status.idle":"2022-12-31T18:41:15.047550Z","shell.execute_reply.started":"2022-12-31T18:41:15.036001Z","shell.execute_reply":"2022-12-31T18:41:15.046506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\noutputs, targets = validation(epoch)\noutputs = np.array(outputs) >= 0.5\naccuracy = metrics.accuracy_score(targets, outputs)\nrecall = metrics.recall_score(targets, outputs, average='micro')\nf1_score_micro = metrics.f1_score(targets, outputs, average='micro')\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\nprint(f\"Accuracy Score = {accuracy}\")\nprint(f\"Recall Score = {recall}\")\nprint(f\"F1 Score = {f1_score_micro}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-31T17:23:48.146190Z","iopub.execute_input":"2022-12-31T17:23:48.146537Z","iopub.status.idle":"2022-12-31T17:23:53.558194Z","shell.execute_reply.started":"2022-12-31T17:23:48.146507Z","shell.execute_reply":"2022-12-31T17:23:53.556672Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  del sys.path[0]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy Score = 0.7704918032786885\nRecall Score = 0.7704918032786885\nF1 Score = 0.7704918032786885\n","output_type":"stream"}]},{"cell_type":"code","source":"for i,stance in enumerate(test.stance) :\n    if stance == [0,1,0]:\n        test['stance'].iloc[i] = 0\n    elif stance == [0,0,1] :\n        test['stance'].iloc[i] = 1\n    elif stance == [1,0,0] :\n        test['stance'].iloc[i] = -1","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:12:22.380027Z","iopub.execute_input":"2022-12-31T19:12:22.380438Z","iopub.status.idle":"2022-12-31T19:12:22.459110Z","shell.execute_reply.started":"2022-12-31T19:12:22.380396Z","shell.execute_reply":"2022-12-31T19:12:22.458128Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datetime import datetime\ntest['created_at'] = test['created_at'].astype('datetime64[ns]')\ntest.sort_values(by='created_at', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:12:25.339629Z","iopub.execute_input":"2022-12-31T19:12:25.339999Z","iopub.status.idle":"2022-12-31T19:12:25.347595Z","shell.execute_reply.started":"2022-12-31T19:12:25.339966Z","shell.execute_reply":"2022-12-31T19:12:25.346566Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure([go.Scatter(x=test['created_at'], y=test['stance'])])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:14:18.716285Z","iopub.execute_input":"2022-12-31T19:14:18.716967Z","iopub.status.idle":"2022-12-31T19:14:18.971420Z","shell.execute_reply.started":"2022-12-31T19:14:18.716931Z","shell.execute_reply":"2022-12-31T19:14:18.970319Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"8ca67e60-57d3-481e-bade-d4322bdace41\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8ca67e60-57d3-481e-bade-d4322bdace41\")) {                    Plotly.newPlot(                        \"8ca67e60-57d3-481e-bade-d4322bdace41\",                        [{\"x\":[\"2009-07-16T11:41:43\",\"2009-09-02T17:25:21\",\"2009-12-10T04:33:21\",\"2010-01-10T13:47:05\",\"2010-01-23T00:04:38\",\"2010-01-24T21:26:01\",\"2010-06-20T16:26:52\",\"2010-06-22T11:13:17\",\"2011-03-20T20:46:03\",\"2011-06-19T20:55:06\",\"2011-06-22T20:44:19\",\"2012-07-05T05:10:26\",\"2012-10-03T02:17:43\",\"2012-11-16T02:51:50\",\"2012-11-29T01:07:09\",\"2013-02-13T12:15:51\",\"2013-04-29T08:25:38\",\"2013-08-05T23:35:15\",\"2013-08-30T11:51:26\",\"2014-10-23T10:19:41\",\"2014-12-05T20:16:29\",\"2014-12-29T15:23:57\",\"2015-01-20T17:16:30\",\"2015-01-30T04:03:53\",\"2015-02-14T07:13:37\",\"2015-03-15T10:56:19\",\"2015-03-31T13:14:06\",\"2015-05-01T14:54:30\",\"2015-05-26T07:19:25\",\"2015-08-03T13:56:49\",\"2015-12-07T08:13:34\",\"2015-12-07T21:29:30\",\"2015-12-08T14:23:46\",\"2015-12-15T01:43:32\",\"2015-12-18T21:43:42\",\"2015-12-26T21:06:17\",\"2016-02-03T04:38:52\",\"2016-02-03T13:58:05\",\"2016-02-04T15:38:37\",\"2016-02-22T19:24:11\",\"2016-02-27T15:21:08\",\"2016-05-03T22:16:59\",\"2016-05-05T11:35:10\",\"2016-05-12T12:55:37\",\"2016-05-18T19:39:56\",\"2016-06-20T10:06:57\",\"2016-07-06T14:35:25\",\"2016-07-20T11:52:51\",\"2016-08-20T13:56:36\",\"2016-09-11T01:18:49\",\"2016-09-27T01:20:30\",\"2016-10-07T17:52:19\",\"2016-12-19T23:00:24\",\"2017-01-05T10:10:41\",\"2017-01-31T14:35:38\",\"2017-02-03T09:44:18\",\"2017-05-18T19:57:07\",\"2017-06-05T17:45:07\",\"2017-06-09T08:21:03\",\"2017-09-26T00:11:30\",\"2017-10-05T01:44:12\",\"2017-10-05T21:05:25\",\"2017-10-06T15:17:34\",\"2017-10-13T19:13:54\",\"2017-10-19T15:36:07\",\"2017-10-24T16:38:18\",\"2017-11-01T14:50:44\",\"2017-11-03T21:08:52\",\"2017-11-08T16:03:35\",\"2017-11-20T07:50:38\",\"2017-11-24T18:39:38\",\"2017-11-25T09:21:34\",\"2017-11-25T23:04:15\",\"2017-11-26T20:23:34\",\"2017-12-01T23:20:39\",\"2017-12-02T20:30:34\",\"2017-12-06T23:45:10\",\"2017-12-07T07:52:51\",\"2017-12-10T14:21:13\",\"2017-12-12T16:45:14\",\"2017-12-16T20:03:19\",\"2017-12-21T06:53:55\",\"2017-12-27T23:52:07\",\"2017-12-29T04:10:20\",\"2017-12-29T04:44:17\",\"2017-12-29T07:52:54\",\"2017-12-29T15:28:57\",\"2017-12-29T16:57:53\",\"2017-12-30T09:54:52\",\"2017-12-31T20:45:10\",\"2018-01-03T01:17:15\",\"2018-01-09T00:18:35\",\"2018-01-12T06:41:01\",\"2018-01-12T17:08:32\",\"2018-01-23T00:30:36\",\"2018-01-28T08:41:41\",\"2018-01-30T01:09:51\",\"2018-01-30T06:37:00\",\"2018-02-08T08:00:02\",\"2018-02-10T12:36:22\",\"2018-02-10T23:12:14\",\"2018-02-13T15:20:34\",\"2018-02-14T18:52:49\",\"2018-02-22T04:54:51\",\"2018-02-27T16:04:41\",\"2018-02-27T17:43:02\",\"2018-03-02T13:49:05\",\"2018-03-08T10:31:27\",\"2018-03-11T14:28:50\",\"2018-03-14T05:26:00\",\"2018-03-14T13:34:16\",\"2018-03-15T13:58:24\",\"2018-03-20T19:17:00\",\"2018-03-27T16:57:25\",\"2018-03-31T13:36:02\",\"2018-04-16T22:22:24\",\"2018-04-30T03:17:45\",\"2018-05-06T18:15:16\",\"2018-05-18T04:56:22\",\"2018-05-31T20:07:00\",\"2018-06-01T16:00:17\",\"2018-06-05T18:48:36\",\"2018-06-16T14:17:12\",\"2018-07-05T19:21:55\",\"2018-08-13T18:35:41\",\"2018-08-14T01:17:39\",\"2018-08-16T11:49:13\",\"2018-08-23T23:04:28\",\"2018-08-24T00:09:47\",\"2018-08-24T06:08:14\",\"2018-08-24T16:36:06\",\"2018-09-03T16:05:27\",\"2018-09-04T13:02:33\",\"2018-09-06T19:40:46\",\"2018-09-07T14:48:12\",\"2018-09-07T18:28:24\",\"2018-09-19T01:53:47\",\"2018-09-25T22:44:42\",\"2018-09-26T20:55:35\",\"2018-10-09T02:57:40\",\"2018-10-09T11:13:08\",\"2018-10-11T20:50:18\",\"2018-10-14T03:00:42\",\"2018-10-18T13:53:02\",\"2018-10-20T02:55:55\",\"2018-10-20T14:35:02\",\"2018-11-27T21:44:22\",\"2018-11-28T14:36:08\",\"2018-11-28T21:33:20\",\"2018-12-01T22:14:18\",\"2018-12-02T17:39:21\",\"2018-12-03T09:57:17\",\"2018-12-07T18:42:56\",\"2018-12-08T04:01:04\",\"2018-12-11T01:19:06\",\"2018-12-23T11:40:05\",\"2018-12-29T01:12:26\",\"2019-01-01T03:11:31\",\"2019-01-05T02:26:29\",\"2019-01-07T13:15:05\",\"2019-01-07T17:02:28\",\"2019-04-17T19:49:27\",\"2019-04-18T02:36:53\",\"2019-04-20T02:58:57\",\"2019-04-20T07:50:01\",\"2019-04-24T11:10:10\",\"2019-04-24T11:51:31\",\"2019-04-25T00:11:35\",\"2019-04-28T13:38:33\",\"2019-04-29T18:54:54\",\"2019-04-30T09:08:23\",\"2019-05-02T21:03:19\",\"2019-05-03T13:03:21\",\"2019-05-04T09:11:53\",\"2019-05-06T14:59:19\",\"2019-05-07T08:31:31\",\"2019-05-09T10:11:37\",\"2019-05-09T10:26:24\",\"2019-05-10T22:25:06\",\"2019-05-11T03:43:09\",\"2019-05-16T03:15:38\",\"2019-05-18T03:44:47\",\"2019-05-19T02:35:36\"],\"y\":[1,1,0,1,-1,-1,1,1,0,-1,1,0,1,0,0,-1,1,1,0,1,1,1,-1,1,1,0,1,-1,1,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,-1,1,1,1,1,1,0,-1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,-1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,-1,0,1,1,1,1,1,1,0,1,-1,1,-1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8ca67e60-57d3-481e-bade-d4322bdace41');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]}]}